{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88219,"status":"ok","timestamp":1704263498859,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"},"user_tz":-330},"id":"WRwbxQ-d_d2Y","outputId":"2e385f70-7997-4926-eedf-11b4f0a37661"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on the test set: 86.43%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Define the neural network\n","class Neural(nn.Module):\n","  def __init__(self):\n","    super(Neural,self).__init__()\n","    self.fc1=nn.Linear(28*28,128)\n","    self.fc2=nn.Linear(128,10)\n","  def forward(self,x):\n","    x=x.view(-1,28*28)\n","    x=torch.relu(self.fc1(x))\n","    x=self.fc2(x)\n","    return x\n","net=Neural()\n","\n","# Define transformation for data\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","# Load Fashion MNIST dataset\n","train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n","test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n","\n","# Create data loaders\n","train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n","\n","# Initialize the neural network\n","net = NeuralNetwork()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n","\n","# Training the neural network\n","num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = net(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the neural network on the test set and calculate accuracy\n","net.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        output = net(data)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","accuracy = correct / total\n","print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7023,"status":"ok","timestamp":1704264108211,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"},"user_tz":-330},"id":"Py2tH8fv_y1B","outputId":"7f19872d-4f6e-46b6-ea4c-ec45b6241a6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Accuracy on the test set: 74.28%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Load Iris dataset\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Convert NumPy arrays to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Create PyTorch datasets and data loaders\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n","\n","# Define the neural network\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = nn.Linear(4, 8)\n","        self.relu1 = nn.ReLU()\n","        self.fc2 = nn.Linear(8, 3)  # 3 classes for Iris dataset\n","\n","    def forward(self, x):\n","        x = self.relu1(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Initialize the neural network\n","net = NeuralNetwork()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01)\n","\n","# Training the neural network\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = net(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the neural network on the test set and calculate accuracy\n","net.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        output = net(data)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","accuracy = correct / total\n","print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1484,"status":"ok","timestamp":1704264327756,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"},"user_tz":-330},"id":"DVfUIyM-B3ny","outputId":"35af9e29-ec05-4655-80f8-8bb3321a4346"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on the test set: 93.33%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Define the neural network\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = nn.Linear(4, 128)\n","        self.relu1 = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 10)  # Assuming 10 classes for simplicity\n","\n","    def forward(self, x):\n","        x = self.relu1(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Load Iris dataset\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Convert NumPy arrays to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Create PyTorch datasets and data loaders\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n","\n","# Initialize the neural network\n","net = NeuralNetwork()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01)\n","\n","# Training the neural network\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = net(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the neural network on the test set and calculate accuracy\n","net.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        output = net(data)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","accuracy = correct / total\n","print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_0vKGKlEddJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOetZ1NviNYBW1TAWEQ9fTi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}