{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPmoC/D80grfz+urjRi3h0h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":32,"metadata":{"id":"ZrqMi4IymjV2","executionInfo":{"status":"ok","timestamp":1704263000727,"user_tz":-330,"elapsed":811,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"outputs":[],"source":["import torch\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","source":["transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081))])"],"metadata":{"id":"VcsgDt5sn-Y6","executionInfo":{"status":"ok","timestamp":1704263001897,"user_tz":-330,"elapsed":40,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["train_dataset=datasets.MNIST('data',train=True,download=True,transform=transform)"],"metadata":{"id":"sRBdKmznnW9O","executionInfo":{"status":"ok","timestamp":1704263001897,"user_tz":-330,"elapsed":39,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)"],"metadata":{"id":"EEXTM3rgp4kj","executionInfo":{"status":"ok","timestamp":1704263001898,"user_tz":-330,"elapsed":39,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["2 Layers"],"metadata":{"id":"b65sKfeQ-sGu"}},{"cell_type":"code","source":["class Neural(nn.Module):\n","  def __init__(self):\n","    super(Neural,self).__init__()\n","    self.fc1=nn.Linear(28*28,128)\n","    self.fc2=nn.Linear(128,10)\n","  def forward(self,x):\n","    x=x.view(-1,28*28)\n","    x=torch.relu(self.fc1(x))\n","    x=self.fc2(x)\n","    return x\n","net=Neural()"],"metadata":{"id":"h-0wx1miqYNm","executionInfo":{"status":"ok","timestamp":1704263001898,"user_tz":-330,"elapsed":39,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["criterion=nn.CrossEntropyLoss()\n","optimizer=optim.SGD(net.parameters(),lr=0.01,momentum=0.5)\n"],"metadata":{"id":"0mWeOB3o2Rqx","executionInfo":{"status":"ok","timestamp":1704263001899,"user_tz":-330,"elapsed":39,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["\n","num_epochs=10\n","for epoch in range(num_epochs):\n","  for batch_idx,(data,target) in enumerate (train_loader):\n","    optimizer.zero_grad()\n","    output=net(data)\n","    loss =criterion(output,target)\n","    loss.backward()\n","    optimizer.step()\n","    if batch_idx % 100==0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVUXH0fC2UOX","executionInfo":{"status":"ok","timestamp":1704263139431,"user_tz":-330,"elapsed":137570,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"988700b1-2953-439b-b9e3-2e106ce7c100"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.322123\n","Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.700196\n","Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.325096\n","Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.434351\n","Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.356475\n","Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.365599\n","Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.374719\n","Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.171741\n","Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.375491\n","Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.165749\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.233791\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.109723\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.240269\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.227564\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.144276\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.384269\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.215375\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.314864\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.261629\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.348410\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.169489\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.197385\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.287488\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.202145\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.135811\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.251265\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.189717\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.146643\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.211920\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.089165\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.223064\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.207436\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.204850\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.213069\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.105753\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.189159\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.167678\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.332195\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.162301\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.196733\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.111784\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.090080\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.120852\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.109266\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.147181\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.174301\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.107371\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.075699\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.133012\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.184713\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.077252\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.095454\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.071534\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.203493\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.027397\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.088729\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.053894\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.212497\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.083643\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.171264\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.267486\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.051344\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.112536\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.153086\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.027770\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.211279\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.117124\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.023931\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.077009\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.124883\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.166447\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.142044\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.079289\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.065688\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.073439\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.035363\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.036279\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.112074\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.164190\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.133355\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.051927\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.067973\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.025153\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.047765\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.187779\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.155959\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.059731\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.077476\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.043755\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.025410\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.036676\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.101142\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.246211\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.148165\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.010628\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.060190\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.138879\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.150574\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.029596\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.169720\n"]}]},{"cell_type":"code","source":["test_dataset=datasets.MNIST('data',train=False,download=True,transform=transform)\n","test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=1000,shuffle=True)\n","correct=0\n","total=0\n","with torch.no_grad():\n","  output=net(data)\n","  _,predicted=torch.max(output.data,1)\n","  total+=target.size(0)\n","  correct+=(predicted==target).sum().item()"],"metadata":{"id":"zjgDjQYL2WoR","executionInfo":{"status":"ok","timestamp":1704263139432,"user_tz":-330,"elapsed":55,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkS_-wbI2bcA","executionInfo":{"status":"ok","timestamp":1704263139432,"user_tz":-330,"elapsed":51,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"c80df2df-907c-4fe9-9571-1213d3c3d2c4"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 100 %\n"]}]},{"cell_type":"markdown","source":["3 Layers"],"metadata":{"id":"Yyu49UQb-7Ag"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Neural(nn.Module):\n","    def __init__(self):\n","        super(Neural, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 128)\n","        self.fc2 = nn.Linear(128, 64)  # Added layer with 64 hidden units\n","        self.fc3 = nn.Linear(64, 10)   # Output layer with 10 units (assuming it's a classification task)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Creating an instance of the Neural network\n","net = Neural()\n"],"metadata":{"id":"msVb3epT2eRv","executionInfo":{"status":"ok","timestamp":1704263139433,"user_tz":-330,"elapsed":46,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","\n","# Assuming you have already defined the Neural network class\n","\n","# Creating an instance of the Neural network\n","net = Neural()\n","\n","# Defining the cross-entropy loss\n","criterion = nn.CrossEntropyLoss()\n","\n","# Defining the SGD optimizer with learning rate and momentum\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n"],"metadata":{"id":"qg1UWKq87OvM","executionInfo":{"status":"ok","timestamp":1704263139433,"user_tz":-330,"elapsed":45,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["num_epochs=10\n","for epoch in range(num_epochs):\n","  for batch_idx,(data,target) in enumerate (train_loader):\n","    optimizer.zero_grad()\n","    output=net(data)\n","    loss =criterion(output,target)\n","    loss.backward()\n","    optimizer.step()\n","    if batch_idx % 100==0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FUI5pn37kJg","executionInfo":{"status":"ok","timestamp":1704263274966,"user_tz":-330,"elapsed":135577,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"73ef095f-428e-4f93-b8da-acd064277dc4"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.324957\n","Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.312914\n","Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.565691\n","Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.405313\n","Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.565849\n","Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.584613\n","Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.347246\n","Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.449537\n","Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.305124\n","Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.414127\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.187055\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.272545\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.228892\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.097357\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.197981\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.095190\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.154922\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.144886\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.094929\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.149872\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.100557\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.269802\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.062146\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.162509\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.246924\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.245570\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.148020\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.187405\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.183137\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.140835\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.213467\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.167269\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.167991\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.204039\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.187979\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.176726\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.194986\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.169985\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.134883\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.084170\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.075205\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.235397\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.212422\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.367704\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.078207\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.076615\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.079061\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.122768\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.126307\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.083269\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.149178\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.079579\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.072961\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.083671\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.068247\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.080220\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.074870\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.174470\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.047826\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.029455\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.264235\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.111459\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.149142\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.026846\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.055137\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.084487\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.111755\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.020094\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.228727\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.074918\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.070942\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.051392\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.166442\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.109395\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.172755\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.079496\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.111650\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.062705\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.113190\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.014000\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.018709\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.087737\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.028635\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.081919\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.019839\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.016755\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.065787\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.070523\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.084232\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.082756\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.068588\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.026850\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.158669\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.128621\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.135444\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.068587\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.027828\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.025706\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.011957\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.157731\n"]}]},{"cell_type":"code","source":["print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLV5Z8OZ7YJ4","executionInfo":{"status":"ok","timestamp":1704263276949,"user_tz":-330,"elapsed":1994,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"8e623042-e9d2-4490-ec7d-287a4917da42"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 100 %\n"]}]},{"cell_type":"markdown","source":["4 Layers"],"metadata":{"id":"-dRhxCwo-9oH"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Neural(nn.Module):\n","    def __init__(self):\n","        super(Neural, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)  # Added layer with 32 hidden units\n","        self.fc4 = nn.Linear(32, 10)  # Output layer with 10 units (assuming it's a classification task)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = torch.relu(self.fc3(x))  # Applying ReLU to the output of the third layer\n","        x = self.fc4(x)\n","        return x\n","\n","# Creating an instance of the Neural network\n","net = Neural()\n"],"metadata":{"id":"d9hnxba08rdr","executionInfo":{"status":"ok","timestamp":1704263276950,"user_tz":-330,"elapsed":26,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","\n","# Assuming you have already defined the Neural network class\n","\n","# Creating an instance of the Neural network\n","net = Neural()\n","\n","# Defining the cross-entropy loss\n","criterion = nn.CrossEntropyLoss()\n","\n","# Defining the SGD optimizer with learning rate and momentum\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1704263276957,"user_tz":-330,"elapsed":32,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"id":"US2JhF66-blb"},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["num_epochs=10\n","for epoch in range(num_epochs):\n","  for batch_idx,(data,target) in enumerate (train_loader):\n","    optimizer.zero_grad()\n","    output=net(data)\n","    loss =criterion(output,target)\n","    loss.backward()\n","    optimizer.step()\n","    if batch_idx % 100==0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ekLWRFm8z6G","executionInfo":{"status":"ok","timestamp":1704263413520,"user_tz":-330,"elapsed":136593,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"c562a413-d621-417c-8f9c-f93bf97985fd"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.303870\n","Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.173894\n","Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.409392\n","Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.666046\n","Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.492926\n","Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.355920\n","Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.731350\n","Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.312547\n","Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.141837\n","Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.381727\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.350916\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.223313\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.242046\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.261907\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.207213\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.119775\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.259781\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.332927\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.544796\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.398289\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.132550\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.281893\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.070709\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.215320\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.618383\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.233377\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.243987\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.091523\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.140406\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.200725\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.118870\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.053907\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.167283\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.173432\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.152595\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.154662\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.111735\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.192609\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.109376\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.247718\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.187575\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.100824\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.090404\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.119124\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.070882\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.154049\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.042342\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.114909\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.061444\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.027597\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.153646\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.057395\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.112917\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.132756\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.045946\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.094905\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.028458\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.061912\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.043250\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.031490\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.141107\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.041226\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.045702\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.123610\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.165604\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.053729\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.043559\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.027816\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.088110\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.061636\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.108275\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.237496\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.029950\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.062796\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.080119\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.118148\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.021914\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.016199\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.075100\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.056687\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.052297\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.021200\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.101989\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.042963\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.062173\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.193199\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.052707\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.081648\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.107552\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.098834\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.033002\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.051560\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.046286\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.077331\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.074040\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.017626\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.027588\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.020850\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.090716\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.075173\n"]}]},{"cell_type":"code","source":["print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2SMC-1f82pq","executionInfo":{"status":"ok","timestamp":1704263413521,"user_tz":-330,"elapsed":85,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"e8f6e600-84cf-418e-837a-9d78968a3d37"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 100 %\n"]}]},{"cell_type":"markdown","source":["4 Layers"],"metadata":{"id":"5vunCmXR_Bqv"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Neural(nn.Module):\n","    def __init__(self):\n","        super(Neural, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 16)  # Added layer with 16 hidden units\n","        self.fc5 = nn.Linear(16, 10)  # Output layer with 10 units (assuming it's a classification task)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = torch.relu(self.fc3(x))\n","        x = torch.relu(self.fc4(x))  # Applying ReLU to the output of the fourth layer\n","        x = self.fc5(x)\n","        return x\n","\n","# Creating an instance of the Neural network\n","net = Neural()\n"],"metadata":{"id":"kfNab7va9kDj","executionInfo":{"status":"ok","timestamp":1704263413522,"user_tz":-330,"elapsed":34,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","\n","# Assuming you have already defined the Neural network class\n","\n","# Creating an instance of the Neural network\n","net = Neural()\n","\n","# Defining the cross-entropy loss\n","criterion = nn.CrossEntropyLoss()\n","\n","# Defining the SGD optimizer with learning rate and momentum\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1704263413523,"user_tz":-330,"elapsed":34,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"id":"3tPxfvdy_GM1"},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["num_epochs=10\n","for epoch in range(num_epochs):\n","  for batch_idx,(data,target) in enumerate (train_loader):\n","    optimizer.zero_grad()\n","    output=net(data)\n","    loss =criterion(output,target)\n","    loss.backward()\n","    optimizer.step()\n","    if batch_idx % 100==0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704263551137,"user_tz":-330,"elapsed":137645,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"cdf81f36-aea4-4d62-cc8a-930c3b2f08d3","id":"UdemTU54-Rf-"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.347458\n","Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.308265\n","Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.243732\n","Train Epoch: 0 [19200/60000 (32%)]\tLoss: 1.990006\n","Train Epoch: 0 [25600/60000 (43%)]\tLoss: 1.671362\n","Train Epoch: 0 [32000/60000 (53%)]\tLoss: 1.219724\n","Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.826849\n","Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.686223\n","Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.608627\n","Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.621957\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.405835\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.300442\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.426367\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.248582\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.348898\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.217359\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.328232\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.279021\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.127598\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.414023\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.405624\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.224618\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.255821\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.268710\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.138146\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.127458\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.141908\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.286962\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.198049\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.172917\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.288662\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.230333\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.320260\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.253286\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.170572\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.136114\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.073395\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.077299\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.064235\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.105079\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.127611\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.078624\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.151351\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.202119\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.049648\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.152281\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.075407\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.037035\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.067337\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.067794\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.139864\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.083792\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.084682\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.246852\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.110681\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.147811\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.116360\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.029625\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.131957\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.059608\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.135909\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.086435\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.024865\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.041173\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.033083\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.034445\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.078877\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.078628\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.076357\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.136543\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.128004\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.098147\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.039815\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.158440\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.113595\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.044146\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.073443\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.117828\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.071461\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.030922\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.060190\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.028945\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.033662\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.041073\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.061843\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.036576\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.053012\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.166928\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009308\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.042510\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.098710\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.044696\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.032623\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.077608\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.221905\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.079331\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.015669\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.044658\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.027028\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.152327\n"]}]},{"cell_type":"code","source":["print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ag2JGYy-Rxv","executionInfo":{"status":"ok","timestamp":1704263551138,"user_tz":-330,"elapsed":58,"user":{"displayName":"Harisowndharya V","userId":"11987712687495952677"}},"outputId":"47292f10-9d2f-475a-8f79-511d9cc05c2f"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 100 %\n"]}]}]}